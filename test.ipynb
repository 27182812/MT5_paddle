{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n"
     ]
    }
   ],
   "source": [
    "import paddle, paddlenlp\n",
    "import torch, transformers\n",
    "import numpy as np\n",
    "from transformers import MT5Model as PTMT5Model\n",
    "from transformers import T5Tokenizer as PTT5Tokenizer\n",
    "from paddlenlp.transformers.mt5 import MT5Model as PDMT5MODEL\n",
    "from paddlenlp.transformers.mt5 import T5Tokenizer as PDT5Tokenizer\n",
    "from reprod_log import ReprodLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "file ./mt5-large\\config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [259, 29230, 288, 2225, 421, 93575, 305, 421, 93575, 272, 280, 325, 309, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [259, 29230, 288, 2225, 421, 93575, 305, 421, 93575, 272, 280, 325, 309, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "### 对齐tokenizer\n",
    "text = \"Welcome to use paddle and paddlenlp!\"\n",
    "torch_tokenizer = PTT5Tokenizer.from_pretrained(\"./mt5-large\")\n",
    "paddle_tokenizer = PDT5Tokenizer.from_pretrained(\"./mt5-large\")\n",
    "torch_inputs = torch_tokenizer(text)\n",
    "paddle_inputs = paddle_tokenizer(text)\n",
    "print(torch_inputs)\n",
    "print(paddle_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/QYS/Desktop/torch/mt5-large were not used when initializing MT5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MT5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MT5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "file ./mt5-large\\config.json not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {'input_ids': tensor([[ 10969,    443, 209522,    295,    259,   8992,    261,    259,   3648,\n",
      "           8104,    672,  53764,   2100,   8497,    281,  55984,    278,    260,\n",
      "              1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "labels {'input_ids': tensor([[ 54620, 191743,    281,  55984,    278,    260,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "torch_prediction_logits shape:(1, 7, 1024)\n",
      "torch_prediction_logits:[[[ 0.28420416 -0.50179034 -0.04449071 ... -0.1624943  -0.04400842\n",
      "    0.1341146 ]\n",
      "  [ 0.12788972 -0.3753653  -0.14871678 ... -0.19723159 -0.03361434\n",
      "    0.10348243]\n",
      "  [ 0.30298987 -0.50692534 -0.28211042 ...  0.04345986  0.06924342\n",
      "   -0.32323718]\n",
      "  ...\n",
      "  [ 0.11287715 -0.26105925 -0.42680943 ... -0.03731987 -0.1992596\n",
      "   -0.4413458 ]\n",
      "  [ 0.2958529   0.04502446  0.17576706 ...  0.12110859  0.11719192\n",
      "   -0.15076399]\n",
      "  [ 0.18357936 -0.164996   -0.08541787 ...  0.04477478 -0.07690276\n",
      "   -0.22456217]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2021-10-17 16:11:42,141] [    INFO]\u001b[0m - Weights from pretrained model not used in MT5Model: ['lm_head.weight']\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {'input_ids': Tensor(shape=[1, 19], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
      "       [[10969 , 443   , 209522, 295   , 259   , 8992  , 261   , 259   , 3648  , 8104  , 672   , 53764 , 2100  , 8497  , 281   , 55984 , 278   , 260   , 1     ]]), 'token_type_ids': Tensor(shape=[1, 19], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
      "       [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "labels {'input_ids': Tensor(shape=[1, 7], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
      "       [[54620 , 191743, 281   , 55984 , 278   , 260   , 1     ]]), 'token_type_ids': Tensor(shape=[1, 7], dtype=int32, place=CPUPlace, stop_gradient=True,\n",
      "       [[0, 0, 0, 0, 0, 0, 0]])}\n",
      "paddle_prediction_logits shape:(1, 7, 1024)\n",
      "paddle_prediction_logits:[[[ 0.284203   -0.5017895  -0.0444912  ... -0.1624946  -0.04400791\n",
      "    0.13411516]\n",
      "  [ 0.12789306 -0.3753674  -0.14871463 ... -0.19723125 -0.03361408\n",
      "    0.10348433]\n",
      "  [ 0.30298844 -0.50692296 -0.28211102 ...  0.04345934  0.06924341\n",
      "   -0.32323664]\n",
      "  ...\n",
      "  [ 0.11287489 -0.26105753 -0.4268134  ... -0.0373196  -0.19925873\n",
      "   -0.4413452 ]\n",
      "  [ 0.29585823  0.04502082  0.17576881 ...  0.12110993  0.1171912\n",
      "   -0.15076649]\n",
      "  [ 0.1835809  -0.16499303 -0.08541968 ...  0.04477417 -0.07690632\n",
      "   -0.22456099]]]\n",
      "mean difference: tensor(2.0390e-06)\n",
      "max difference: tensor(0.0004)\n"
     ]
    }
   ],
   "source": [
    "article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n",
    "summary = \"Weiter Verhandlung in Syrien.\"\n",
    "\n",
    "reprod_logger = ReprodLogger()\n",
    "\n",
    "# torch output\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import MT5Model, T5Tokenizer\n",
    "\n",
    "PREFIX = \"C:/Users/QYS/Desktop/\"\n",
    "torch_model = MT5Model.from_pretrained(f\"{PREFIX}torch/mt5-large\")\n",
    "torch_tokenizer = T5Tokenizer.from_pretrained(\"./mt5-large\")\n",
    "torch_model.eval()\n",
    "# print(\"111\",torch_model.dummy_inputs)\n",
    "\n",
    "torch_inputs = torch_tokenizer(article, return_tensors=\"pt\")\n",
    "with torch_tokenizer.as_target_tokenizer():\n",
    "    labels = torch_tokenizer(summary, return_tensors=\"pt\")\n",
    "print(\"input\", torch_inputs)\n",
    "print(\"labels\", labels)\n",
    "torch_outputs = torch_model(input_ids=torch_inputs[\"input_ids\"], decoder_input_ids=labels[\"input_ids\"])\n",
    "# print(\"output\", torch_outputs)\n",
    "torch_logits = torch_outputs.last_hidden_state\n",
    "torch_array = torch_logits.cpu().detach().numpy()\n",
    "print(\"torch_prediction_logits shape:{}\".format(torch_array.shape))\n",
    "print(\"torch_prediction_logits:{}\".format(torch_array))\n",
    "\n",
    "\n",
    "reprod_logger.add(\"logits\", torch_logits.cpu().detach().numpy())\n",
    "reprod_logger.save(\"forward_torch.npy\")\n",
    "\n",
    "\n",
    "# paddle output\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers.mt5 import MT5Model, T5Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# paddle_model = BertForPretraining.from_pretrained(paddle_model_name)\n",
    "paddle_model = MT5Model.from_pretrained(\"mt5-large\")\n",
    "paddle_tokenizer = T5Tokenizer.from_pretrained(\"./mt5-large\")\n",
    "paddle_model.eval()\n",
    "# print(\"111\",paddle_model.dummy_inputs)\n",
    "\n",
    "paddle_inputs = paddle_tokenizer(article)\n",
    "labels = paddle_tokenizer(summary)\n",
    "\n",
    "paddle_inputs = {k:paddle.to_tensor([v]) for (k, v) in paddle_inputs.items()}\n",
    "labels = {k:paddle.to_tensor([v]) for (k, v) in labels.items()}\n",
    "print(\"input\", paddle_inputs)\n",
    "print(\"labels\", labels)\n",
    "paddle_outputs = paddle_model(input_ids=paddle_inputs[\"input_ids\"], decoder_input_ids=labels[\"input_ids\"],return_dict=True)\n",
    "# print(\"output\", paddle_outputs)\n",
    "paddle_logits = paddle_outputs.last_hidden_state\n",
    "paddle_array = paddle_logits.numpy()\n",
    "print(\"paddle_prediction_logits shape:{}\".format(paddle_array.shape))\n",
    "print(\"paddle_prediction_logits:{}\".format(paddle_array))\n",
    "\n",
    "\n",
    "reprod_logger.add(\"logits\", paddle_logits.cpu().detach().numpy())\n",
    "reprod_logger.save(\"forward_paddle.npy\")\n",
    "\n",
    "\n",
    "\n",
    "# the output logits should have the same shape\n",
    "assert torch_array.shape == paddle_array.shape, \"the output logits should have the same shape, but got : {} and {} instead\".format(torch_array.shape, paddle_array.shape)\n",
    "# diff = torch_array - paddle_array\n",
    "# print(np.amax(abs(diff)))\n",
    "# print(np.mean(abs(diff)))\n",
    "a = torch.tensor(torch_array).float()\n",
    "b = torch.tensor(paddle_array).float()\n",
    "meandif = (a - b).abs().mean()\n",
    "maxdif = (a - b).abs().max()\n",
    "print(\"mean difference:\", meandif)\n",
    "print(\"max difference:\", maxdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "k in data2 but not found in data1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3e0cb43c1b0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtorch_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff_helper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"forward_torch.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpaddle_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff_helper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"forward_paddle.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdiff_helper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompare_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaddle_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdiff_helper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"forward_diff.log\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\reprod_log\\ReprodDiffHelper.py\u001b[0m in \u001b[0;36mcompare_info\u001b[1;34m(self, info1, info2)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m     41\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcheck_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_diff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\reprod_log\\compare.py\u001b[0m in \u001b[0;36mcheck_data\u001b[1;34m(data1, data2)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             assert k in data1, 'k in data2 but not found in data1'.format(\n\u001b[1;32m---> 32\u001b[1;33m                 k, data2.keys())\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: k in data2 but not found in data1"
     ]
    }
   ],
   "source": [
    "from reprod_log import ReprodDiffHelper\n",
    "\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"forward_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"forward_paddle.npy\")\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "diff_helper.report(path=\"forward_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt5.shared.weight [250112, 1024]\n",
      "mt5.encoder.embed_tokens.weight [250112, 1024]\n",
      "mt5.encoder.block.0.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.0.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.0.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.0.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight [32, 16]\n",
      "mt5.encoder.block.0.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.0.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.0.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.0.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.0.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.1.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.1.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.1.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.1.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.1.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.1.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.1.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.1.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.1.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.2.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.2.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.2.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.2.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.2.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.2.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.2.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.2.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.2.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.3.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.3.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.3.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.3.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.3.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.3.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.3.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.3.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.3.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.4.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.4.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.4.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.4.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.4.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.4.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.4.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.4.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.4.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.5.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.5.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.5.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.5.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.5.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.5.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.5.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.5.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.5.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.6.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.6.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.6.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.6.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.6.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.6.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.6.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.6.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.6.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.7.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.7.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.7.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.7.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.7.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.7.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.7.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.7.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.7.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.8.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.8.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.8.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.8.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.8.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.8.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.8.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.8.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.8.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.9.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.9.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.9.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.9.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.9.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.9.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.9.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.9.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.9.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.10.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.10.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.10.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.10.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.10.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.10.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.10.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.10.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.10.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.11.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.11.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.11.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.11.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.11.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.11.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.11.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.11.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.11.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.12.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.12.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.12.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.12.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.12.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.12.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.12.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.12.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.12.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.13.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.13.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.13.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.13.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.13.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.13.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.13.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.13.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.13.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.14.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.14.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.14.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.14.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.14.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.14.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.14.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.14.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.14.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.15.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.15.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.15.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.15.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.15.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.15.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.15.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.15.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.15.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.16.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.16.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.16.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.16.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.16.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.16.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.16.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.16.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.16.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.17.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.17.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.17.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.17.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.17.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.17.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.17.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.17.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.17.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.18.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.18.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.18.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.18.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.18.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.18.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.18.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.18.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.18.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.19.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.19.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.19.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.19.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.19.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.19.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.19.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.19.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.19.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.20.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.20.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.20.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.20.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.20.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.20.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.20.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.20.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.20.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.21.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.21.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.21.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.21.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.21.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.21.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.21.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.21.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.21.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.22.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.22.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.22.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.22.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.22.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.22.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.22.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.22.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.22.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.block.23.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.encoder.block.23.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.encoder.block.23.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.encoder.block.23.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.encoder.block.23.layer.0.layer_norm.weight [1024]\n",
      "mt5.encoder.block.23.layer.1.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.encoder.block.23.layer.1.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.encoder.block.23.layer.1.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.encoder.block.23.layer.1.layer_norm.weight [1024]\n",
      "mt5.encoder.final_layer_norm.weight [1024]\n",
      "mt5.decoder.embed_tokens.weight [250112, 1024]\n",
      "mt5.decoder.block.0.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight [32, 16]\n",
      "mt5.decoder.block.0.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.0.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.0.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.0.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.0.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.0.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.0.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.1.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.1.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.1.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.1.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.1.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.1.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.1.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.2.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.2.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.2.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.2.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.2.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.2.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.2.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.3.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.3.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.3.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.3.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.3.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.3.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.3.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.4.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.4.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.4.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.4.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.4.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.4.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.4.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.5.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.5.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.5.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.5.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.5.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.5.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.5.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.6.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.6.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.6.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.6.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.6.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.6.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.6.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.7.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.7.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.7.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.7.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.7.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.7.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.7.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.8.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.8.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.8.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.8.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.8.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.8.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.8.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.9.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.9.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.9.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.9.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.9.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.9.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.9.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.10.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.10.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.10.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.10.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.10.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.10.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.10.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.11.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.11.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.11.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.11.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.11.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.11.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.11.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.12.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.12.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.12.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.12.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.12.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.12.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.12.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.13.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.13.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.13.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.13.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.13.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.13.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.13.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.14.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.14.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.14.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.14.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.14.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.14.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.14.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.15.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.15.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.15.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.15.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.15.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.15.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.15.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.16.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.16.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.16.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.16.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.16.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.16.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.16.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.17.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.17.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.17.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.17.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.17.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.17.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.17.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.18.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.18.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.18.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.18.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.18.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.18.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.18.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.19.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.19.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.19.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.19.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.19.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.19.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.19.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.20.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.20.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.20.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.20.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.20.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.20.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.20.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.21.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.21.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.21.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.21.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.21.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.21.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.21.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.22.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.22.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.22.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.22.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.22.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.22.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.22.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.block.23.layer.0.SelfAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.0.SelfAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.0.SelfAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.0.SelfAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.0.layer_norm.weight [1024]\n",
      "mt5.decoder.block.23.layer.1.EncDecAttention.q.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.1.EncDecAttention.k.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.1.EncDecAttention.v.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.1.EncDecAttention.o.weight [1024, 1024]\n",
      "mt5.decoder.block.23.layer.1.layer_norm.weight [1024]\n",
      "mt5.decoder.block.23.layer.2.DenseReluDense.wi_0.weight [1024, 2816]\n",
      "mt5.decoder.block.23.layer.2.DenseReluDense.wi_1.weight [1024, 2816]\n",
      "mt5.decoder.block.23.layer.2.DenseReluDense.wo.weight [2816, 1024]\n",
      "mt5.decoder.block.23.layer.2.layer_norm.weight [1024]\n",
      "mt5.decoder.final_layer_norm.weight [1024]\n",
      "lm_head.weight [250112, 1024]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "model_file = \"C:/Users/QYS/Desktop/model_state.pdparams\"\n",
    "paddle_state_dict = paddle.load(model_file)\n",
    "for i in paddle_state_dict.keys():\n",
    "    print(i, paddle_state_dict[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared.weight torch.Size([250112, 1024])\n",
      "encoder.embed_tokens.weight torch.Size([250112, 1024])\n",
      "encoder.block.0.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.0.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.0.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.0.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 16])\n",
      "encoder.block.0.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.0.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.0.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.0.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.1.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.1.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.1.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.1.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.1.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.1.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.1.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.1.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.2.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.2.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.2.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.2.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.2.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.2.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.2.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.2.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.3.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.3.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.3.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.3.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.3.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.3.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.3.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.3.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.4.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.4.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.4.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.4.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.4.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.4.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.4.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.4.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.5.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.5.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.5.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.5.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.5.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.5.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.5.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.5.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.6.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.6.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.6.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.6.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.6.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.6.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.6.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.6.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.7.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.7.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.7.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.7.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.7.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.7.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.7.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.7.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.8.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.8.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.8.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.8.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.8.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.8.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.8.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.8.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.9.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.9.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.9.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.9.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.9.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.9.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.9.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.9.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.10.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.10.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.10.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.10.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.10.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.10.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.10.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.10.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.11.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.11.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.11.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.11.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.11.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.11.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.11.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.11.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.12.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.12.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.12.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.12.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.12.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.12.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.12.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.12.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.13.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.13.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.13.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.13.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.13.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.13.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.13.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.13.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.14.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.14.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.14.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.14.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.14.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.14.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.14.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.14.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.15.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.15.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.15.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.15.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.15.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.15.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.15.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.15.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.16.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.16.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.16.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.16.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.16.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.16.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.16.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.16.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.17.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.17.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.17.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.17.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.17.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.17.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.17.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.17.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.18.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.18.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.18.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.18.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.18.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.18.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.18.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.18.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.19.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.19.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.19.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.19.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.19.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.19.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.19.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.19.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.20.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.20.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.20.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.20.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.20.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.20.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.20.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.20.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.21.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.21.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.21.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.21.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.21.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.21.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.21.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.21.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.22.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.22.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.22.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.22.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.22.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.22.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.22.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.22.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.23.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "encoder.block.23.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "encoder.block.23.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "encoder.block.23.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "encoder.block.23.layer.0.layer_norm.weight torch.Size([1024])\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "encoder.block.23.layer.1.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "encoder.block.23.layer.1.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "encoder.block.23.layer.1.layer_norm.weight torch.Size([1024])\n",
      "encoder.final_layer_norm.weight torch.Size([1024])\n",
      "decoder.embed_tokens.weight torch.Size([250112, 1024])\n",
      "decoder.block.0.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight torch.Size([32, 16])\n",
      "decoder.block.0.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.0.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.0.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.0.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.0.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.0.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.1.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.1.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.1.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.1.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.1.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.1.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.2.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.2.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.2.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.2.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.2.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.2.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.3.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.3.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.3.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.3.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.3.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.3.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.4.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.4.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.4.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.4.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.4.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.4.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.5.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.5.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.5.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.5.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.5.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.5.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.6.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.6.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.6.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.6.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.6.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.6.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.7.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.7.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.7.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.7.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.7.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.7.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.8.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.8.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.8.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.8.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.8.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.8.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.9.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.9.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.9.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.9.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.9.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.9.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.10.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.10.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.10.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.10.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.10.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.10.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.11.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.11.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.11.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.11.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.11.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.11.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.12.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.12.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.12.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.12.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.12.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.12.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.13.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.13.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.13.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.13.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.13.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.13.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.14.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.14.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.14.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.14.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.14.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.14.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.15.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.15.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.15.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.15.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.15.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.15.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.16.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.16.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.16.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.16.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.16.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.16.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.17.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.17.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.17.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.17.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.17.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.17.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.18.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.18.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.18.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.18.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.18.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.18.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.19.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.19.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.19.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.19.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.19.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.19.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.20.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.20.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.20.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.20.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.20.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.20.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.21.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.21.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.21.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.21.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.21.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.21.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.22.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.22.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.22.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.22.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.22.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.22.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.23.layer.0.SelfAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.0.SelfAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.0.SelfAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.0.SelfAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.0.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.23.layer.1.EncDecAttention.q.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.1.EncDecAttention.k.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.1.EncDecAttention.v.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.1.EncDecAttention.o.weight torch.Size([1024, 1024])\n",
      "decoder.block.23.layer.1.layer_norm.weight torch.Size([1024])\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_0.weight torch.Size([2816, 1024])\n",
      "decoder.block.23.layer.2.DenseReluDense.wi_1.weight torch.Size([2816, 1024])\n",
      "decoder.block.23.layer.2.DenseReluDense.wo.weight torch.Size([1024, 2816])\n",
      "decoder.block.23.layer.2.layer_norm.weight torch.Size([1024])\n",
      "decoder.final_layer_norm.weight torch.Size([1024])\n",
      "lm_head.weight torch.Size([250112, 1024])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_file = \"C:/Users/QYS/Desktop/torch/mt5-large/pytorch_model.bin\"\n",
    "pytorch_state_dict = torch.load(model_file)\n",
    "for i in pytorch_state_dict.keys():\n",
    "    print(i, pytorch_state_dict[i].shape)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
